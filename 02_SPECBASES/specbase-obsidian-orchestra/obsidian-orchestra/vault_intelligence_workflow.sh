#!/bin/bash
# VAULT INTELLIGENCE WORKFLOW - Ongoing Optimization System
# Run this monthly to keep your vault optimized

set -e

VAULT_PATH="."
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
OUTPUT_DIR="vault_intelligence_history"

echo "🧠 VAULT INTELLIGENCE WORKFLOW - MONTHLY OPTIMIZATION"
echo "======================================================================="
echo "📅 Started: $(date)"
echo "📁 Vault: $VAULT_PATH"
echo

# Create history directory
mkdir -p "$OUTPUT_DIR"

# Step 1: Run complete intelligence analysis
echo "🔍 Step 1: Running intelligence analysis..."
python3 obsidian_complete_test.py "$VAULT_PATH"

if [ $? -eq 0 ]; then
    echo "✅ Intelligence analysis completed"

    # Archive the results
    cp -r obsidian_intelligence_complete "$OUTPUT_DIR/analysis_$TIMESTAMP"
    echo "📁 Results archived to: $OUTPUT_DIR/analysis_$TIMESTAMP"
else
    echo "❌ Intelligence analysis failed"
    exit 1
fi

# Step 2: Generate optimization recommendations
echo
echo "🎯 Step 2: Generating optimization recommendations..."
python3 vault_optimizer.py "$VAULT_PATH"

if [ $? -eq 0 ]; then
    echo "✅ Optimization recommendations generated"

    # Archive optimization plans
    cp VAULT_OPTIMIZATION_MASTER_PLAN.md "$OUTPUT_DIR/optimization_plan_$TIMESTAMP.md"
    cp BIDIRECTIONAL_LINKS_GUIDE.md "$OUTPUT_DIR/bidirectional_guide_$TIMESTAMP.md" 2>/dev/null || true
    cp ISOLATED_CONTENT_STRATEGY.md "$OUTPUT_DIR/isolated_strategy_$TIMESTAMP.md" 2>/dev/null || true
    cp COMMUNITY_STRENGTHENING_PLAN.md "$OUTPUT_DIR/community_plan_$TIMESTAMP.md" 2>/dev/null || true

    echo "📋 Optimization plans archived"
else
    echo "❌ Optimization generation failed"
    exit 1
fi

# Step 3: Generate progress report
echo
echo "📊 Step 3: Generating progress report..."

REPORT_FILE="$OUTPUT_DIR/progress_report_$TIMESTAMP.md"

cat > "$REPORT_FILE" << EOF
# 📊 Vault Intelligence Progress Report

**Generated:** $(date)
**Analysis ID:** $TIMESTAMP

## 📈 Current Metrics

EOF

# Extract key metrics from the latest analysis
if [ -f "obsidian_intelligence_complete/complete_intelligence_report.json" ]; then
    python3 -c "
import json

with open('obsidian_intelligence_complete/complete_intelligence_report.json', 'r') as f:
    data = json.load(f)

summary = data['obsidian_intelligence_report']['executive_summary']

print(f'- **Documents:** {summary[\"total_documents\"]:,}')
print(f'- **Connections:** {summary[\"total_connections\"]:,}')
print(f'- **Communities:** {summary[\"communities_detected\"]:,}')
print(f'- **Network Density:** {summary[\"network_density\"]:.4f}')
print(f'- **Avg Connections/Doc:** {summary[\"avg_connections_per_doc\"]:.1f}')
" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" << EOF

## 🏆 Top Influential Nodes

EOF

# Extract top nodes
if [ -f "obsidian_intelligence_complete/complete_intelligence_report.json" ]; then
    python3 -c "
import json

with open('obsidian_intelligence_complete/complete_intelligence_report.json', 'r') as f:
    data = json.load(f)

top_nodes = data['obsidian_intelligence_report']['network_intelligence']['top_influential_nodes'][:10]

for i, (node, score) in enumerate(top_nodes):
    print(f'{i+1}. **{node}** - Score: {score:.2f}')
" >> "$REPORT_FILE"
fi

cat >> "$REPORT_FILE" << EOF

## 🎯 Recommended Actions

### Phase 1: Quick Wins (1-2 hours)
- [ ] Review and enhance top influential nodes
- [ ] Utilize new index pages created
- [ ] Check navigation improvements

### Phase 2: Structural Improvements (2-4 hours)
- [ ] Implement isolated content connections
- [ ] Strengthen sparse communities
- [ ] Add strategic hub documents

### Phase 3: Relationship Enhancement (4-6 hours)
- [ ] Complete bidirectional links
- [ ] Create topic bridges
- [ ] Optimize knowledge flow

## 📁 Generated Files

- 🔍 **Intelligence Analysis:** obsidian_intelligence_complete/
- 🎯 **Master Plan:** VAULT_OPTIMIZATION_MASTER_PLAN.md
- 🔗 **Bidirectional Guide:** BIDIRECTIONAL_LINKS_GUIDE.md
- 🏝️ **Isolation Strategy:** ISOLATED_CONTENT_STRATEGY.md
- 🏘️ **Community Plan:** COMMUNITY_STRENGTHENING_PLAN.md

## 📊 Historical Data

This analysis is archived in: \`$OUTPUT_DIR/analysis_$TIMESTAMP\`

## 🔄 Next Review

**Recommended:** $(date -d '+1 month' 2>/dev/null || date -v+1m 2>/dev/null || echo 'In 1 month')

---
*Generated by Vault Intelligence Workflow*
*Free alternative to InfraNodus (\$600/year)*
EOF

echo "📊 Progress report created: $REPORT_FILE"

# Step 4: Check for improvements since last run
echo
echo "📈 Step 4: Comparing with previous analysis..."

PREVIOUS_ANALYSIS=$(ls -t "$OUTPUT_DIR"/analysis_* 2>/dev/null | sed -n 2p)

if [ -n "$PREVIOUS_ANALYSIS" ] && [ -f "$PREVIOUS_ANALYSIS/complete_intelligence_report.json" ]; then
    echo "📊 Comparing with: $(basename "$PREVIOUS_ANALYSIS")"

    COMPARISON_FILE="$OUTPUT_DIR/comparison_$TIMESTAMP.md"

    python3 -c "
import json
import sys

# Load current analysis
with open('obsidian_intelligence_complete/complete_intelligence_report.json', 'r') as f:
    current = json.load(f)

# Load previous analysis
try:
    with open('$PREVIOUS_ANALYSIS/complete_intelligence_report.json', 'r') as f:
        previous = json.load(f)

    curr_summary = current['obsidian_intelligence_report']['executive_summary']
    prev_summary = previous['obsidian_intelligence_report']['executive_summary']

    print('# 📈 Vault Intelligence Comparison')
    print()
    print('## 📊 Metric Changes')
    print()

    metrics = [
        ('Documents', 'total_documents'),
        ('Connections', 'total_connections'),
        ('Communities', 'communities_detected'),
        ('Network Density', 'network_density'),
        ('Avg Connections/Doc', 'avg_connections_per_doc')
    ]

    for name, key in metrics:
        curr_val = curr_summary[key]
        prev_val = prev_summary[key]
        change = curr_val - prev_val

        if isinstance(curr_val, float):
            change_str = f'{change:+.4f}'
            curr_str = f'{curr_val:.4f}'
        else:
            change_str = f'{change:+,}'
            curr_str = f'{curr_val:,}'

        emoji = '📈' if change > 0 else '📉' if change < 0 else '➡️'
        print(f'- **{name}:** {curr_str} ({change_str}) {emoji}')

    print()
    print('## 🎯 Improvement Summary')

    total_change = curr_summary['total_connections'] - prev_summary['total_connections']
    density_change = curr_summary['network_density'] - prev_summary['network_density']

    if total_change > 0:
        print(f'✅ **Network Growth:** +{total_change:,} new connections discovered')

    if density_change > 0:
        print(f'✅ **Density Improvement:** +{density_change:.4f} better connectivity')

    if total_change > 0 or density_change > 0:
        print('🎉 **Your vault is getting smarter!**')
    else:
        print('📊 **Network stability maintained**')

except Exception as e:
    print(f'⚠️  Could not compare with previous analysis: {e}')
" > "$COMPARISON_FILE"

    echo "📈 Comparison report created: $COMPARISON_FILE"
else
    echo "📊 No previous analysis found for comparison"
fi

# Step 5: Create dashboard update
echo
echo "🎨 Step 5: Updating intelligence dashboard..."

# Update the dashboard with latest metrics
cp vault_intelligence_dashboard.html "$OUTPUT_DIR/dashboard_$TIMESTAMP.html"

echo "🎨 Dashboard archived: $OUTPUT_DIR/dashboard_$TIMESTAMP.html"

# Final summary
echo
echo "🎉 WORKFLOW COMPLETE!"
echo "======================================================================="
echo "📊 Analysis ID: $TIMESTAMP"
echo "📁 All results archived in: $OUTPUT_DIR/"
echo "🎯 Next steps: Review VAULT_OPTIMIZATION_MASTER_PLAN.md"
echo "🔄 Next run: Recommended in 1 month"
echo
echo "📋 Quick Actions:"
echo "1. Open vault_intelligence_dashboard.html in browser"
echo "2. Review $REPORT_FILE"
echo "3. Implement Phase 1 quick wins from master plan"
echo
echo "🚀 Your vault intelligence is continuously evolving!"
echo "💰 Saving \$600/year vs InfraNodus with enhanced features!"
EOF