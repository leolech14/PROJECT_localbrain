#!/usr/bin/env python3
"""
üéØ CANVAS ATOMIC QUERY SNIPER - X-RAY 4K CODEBASE ANALYZER
Multi-Indexer Sniper Tagger Query Gun for Financial Intelligence Platform

REVOLUTIONARY CAPABILITIES:
- Atomic meaning isolation from 480+ files
- Query-based pattern recognition
- Canvas spatial intelligence integration
- Multi-dimensional tagging system
- X-ray vision into entire architectural ecosystem
"""

import os
import json
import re
from pathlib import Path
from typing import Dict, List, Any
from collections import defaultdict, Counter
from datetime import datetime

class CanvasAtomicQuerySniper:
    """
    The Multi-Indexer Sniper Tagger Query Gun with X-ray 4K vision

    Combines Canvas spatial intelligence with atomic content analysis
    """

    def __init__(self):
        self.query_tags = {
            # Financial Intelligence Queries
            'AGENTIC_NATIVE': ['agentic', 'autonomous', 'agent', 'symphony', 'orchestration'],
            'POLICY_ENFORCEMENT': ['policy', 'kill_switch', 'security', 'audit', 'compliance'],
            'BRAZILIAN_FINTECH': ['brazilian', 'brazil', 'open_finance', 'pix', 'irpf', 'mei'],
            'TRINITY_INTELLIGENCE': ['trinity', 'human', 'ai', 'consciousness', 'collaboration'],

            # Architecture Pattern Queries
            'POKER_TABLE_PATTERN': ['data_pool', 'central', 'nucleus', 'shared', 'table'],
            'SYMPHONY_PATTERN': ['orchestrator', 'maestro', 'conductor', 'routing', 'dispatch'],
            'CHANGE_SET_PATTERN': ['change_set', 'approval', 'ledger', 'audit', 'immutable'],
            'SECURITY_FIRST': ['security', 'encryption', 'authentication', 'protection'],

            # Implementation Status Queries
            'PRODUCTION_READY': ['complete', 'production', 'ready', 'implemented', 'tested'],
            'IN_DEVELOPMENT': ['intermediate', 'development', 'progress', 'implementing'],
            'NEEDS_IMPLEMENTATION': ['minimal', 'todo', 'pending', 'required', 'missing'],

            # Technical Complexity Queries
            'HIGH_COMPLEXITY': ['complex', 'sophisticated', 'advanced', 'intricate'],
            'CORE_FOUNDATION': ['foundation', 'core', 'critical', 'essential', 'backbone'],
            'USER_INTERFACE': ['ui', 'interface', 'component', 'widget', 'dashboard'],

            # Content Type Queries
            'MERMAID_DIAGRAMS': ['mermaid', 'graph', 'flowchart', 'mindmap', 'diagram'],
            'TECHNICAL_SPECS': ['specification', 'implementation', 'technical', 'api'],
            'ARCHITECTURAL_DOCS': ['architecture', 'design', 'pattern', 'structure']
        }

        self.canvas_entities = []
        self.atomic_knowledge = {}
        self.spatial_intelligence = {}

    def load_canvas_registry(self, canvas_file: str = "CANVAS VIEW.canvas"):
        """Load Canvas entities with spatial intelligence"""
        print("üó∫Ô∏è Loading Canvas spatial intelligence...")

        with open(canvas_file, 'r') as f:
            canvas_data = json.load(f)

        self.canvas_entities = canvas_data['nodes']
        print(f"üìä Loaded {len(self.canvas_entities)} Canvas entities")

        return canvas_data

    def analyze_file_content(self, file_path: str) -> Dict:
        """Analyze individual file with X-ray precision"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            lines = content.split('\n')

            # Extract front matter
            front_matter = {}
            if lines[0].strip() == '---':
                for i, line in enumerate(lines[1:], 1):
                    if line.strip() == '---':
                        break
                    if ':' in line:
                        key, value = line.split(':', 1)
                        front_matter[key.strip()] = value.strip().strip('"')

            # Apply query-based analysis
            query_matches = {}
            content_lower = content.lower()

            for query_name, keywords in self.query_tags.items():
                matches = [kw for kw in keywords if kw in content_lower]
                if matches:
                    query_matches[query_name] = {
                        'matched_keywords': matches,
                        'match_strength': len(matches) / len(keywords),
                        'confidence': min(1.0, len(matches) * 0.3)
                    }

            # Extract atomic meanings
            atomic_concepts = self._extract_atomic_concepts(content)

            return {
                'file_path': file_path,
                'line_count': len(lines),
                'character_count': len(content),
                'front_matter': front_matter,
                'query_matches': query_matches,
                'atomic_concepts': atomic_concepts,
                'complexity_score': self._calculate_complexity(content, query_matches),
                'architectural_significance': self._assess_architectural_significance(query_matches)
            }

        except Exception as e:
            return {'error': str(e), 'file_path': file_path}

    def _extract_atomic_concepts(self, content: str) -> List[str]:
        """Extract atomic concept units from content"""
        # Extract headers as concept boundaries
        headers = re.findall(r'^#+\s+(.+)$', content, re.MULTILINE)

        # Extract key technical terms
        technical_terms = re.findall(r'\b[A-Z][A-Z_]+[A-Z]\b', content)

        # Extract quoted concepts
        quoted_concepts = re.findall(r'"([^"]+)"', content)

        # Combine unique concepts
        concepts = list(set(headers + technical_terms + quoted_concepts))
        return concepts[:20]  # Top 20 concepts

    def _calculate_complexity(self, content: str, query_matches: Dict) -> str:
        """Calculate content complexity based on multiple factors"""
        lines = len(content.split('\n'))

        # Factor in technical complexity indicators
        complexity_indicators = len(query_matches.get('HIGH_COMPLEXITY', {}).get('matched_keywords', []))
        mermaid_diagrams = content.count('```mermaid')
        code_blocks = content.count('```')

        complexity_score = (
            lines * 0.001 +
            complexity_indicators * 0.1 +
            mermaid_diagrams * 0.2 +
            code_blocks * 0.05
        )

        if complexity_score > 1.5:
            return "very_high"
        elif complexity_score > 1.0:
            return "high"
        elif complexity_score > 0.5:
            return "medium"
        else:
            return "low"

    def _assess_architectural_significance(self, query_matches: Dict) -> str:
        """Assess architectural significance based on query patterns"""
        core_matches = len(query_matches.get('CORE_FOUNDATION', {}).get('matched_keywords', []))
        architecture_matches = len(query_matches.get('ARCHITECTURAL_DOCS', {}).get('matched_keywords', []))

        total_significance = core_matches + architecture_matches

        if total_significance >= 3:
            return "critical"
        elif total_significance >= 2:
            return "high"
        elif total_significance >= 1:
            return "medium"
        else:
            return "low"

    def create_canvas_atomic_registry(self, target_directory: str = ".") -> Dict:
        """Create complete Canvas-integrated atomic registry"""

        print("üéØ CANVAS ATOMIC QUERY SNIPER - ENGAGING X-RAY MODE")
        print("üåå Multi-Indexer Analysis of Financial Intelligence Platform")
        print("=" * 70)

        # Load Canvas spatial data
        canvas_data = self.load_canvas_registry()

        # Create file mapping from Canvas
        canvas_file_map = {}
        for entity in self.canvas_entities:
            if entity['type'] == 'file' and 'file' in entity:
                file_name = entity['file']
                canvas_file_map[file_name] = {
                    'coordinates': {
                        'x': entity['x'],
                        'y': entity['y'],
                        'width': entity['width'],
                        'height': entity['height']
                    },
                    'color': entity.get('color', 'none'),
                    'canvas_id': entity['id']
                }

        print(f"üó∫Ô∏è Mapped {len(canvas_file_map)} Canvas entities")

        # Analyze all markdown files
        print("üîç Beginning X-ray analysis of all specifications...")

        atomic_registry = {
            'metadata': {
                'generated_at': datetime.now().isoformat(),
                'total_files_analyzed': 0,
                'canvas_entities_mapped': len(canvas_file_map),
                'query_patterns_applied': len(self.query_tags)
            },
            'spatial_atomic_mapping': [],
            'query_intelligence': {},
            'architectural_insights': {},
            'atomic_concept_network': {}
        }

        for md_file in Path(target_directory).glob('*.md'):
            if md_file.name.startswith('.'):
                continue

            print(f"üéØ Sniping: {md_file.name}")

            file_analysis = self.analyze_file_content(str(md_file))
            canvas_info = canvas_file_map.get(md_file.name, {})

            # Merge Canvas spatial data with content analysis
            entity_record = {
                'file_name': md_file.name,
                'canvas_position': canvas_info.get('coordinates', {}),
                'canvas_color': canvas_info.get('color', 'none'),
                'canvas_id': canvas_info.get('canvas_id', 'unmapped'),
                'content_analysis': file_analysis,
                'spatial_zone': self._determine_spatial_zone(canvas_info.get('coordinates', {})),
                'architectural_classification': self._classify_architecturally(file_analysis)
            }

            atomic_registry['spatial_atomic_mapping'].append(entity_record)
            atomic_registry['metadata']['total_files_analyzed'] += 1

        # Generate query intelligence summary
        atomic_registry['query_intelligence'] = self._generate_query_intelligence(atomic_registry['spatial_atomic_mapping'])

        print("‚úÖ X-ray analysis complete!")
        print(f"üìä Analyzed {atomic_registry['metadata']['total_files_analyzed']} files")

        return atomic_registry

    def _determine_spatial_zone(self, coordinates: Dict) -> str:
        """Determine which architectural zone based on coordinates"""
        if not coordinates:
            return "unmapped"

        x = coordinates.get('x', 0)

        if x < -10000:
            return "research_highlands"
        elif x < -1000:
            return "orchestration_core"
        elif x < 5000:
            return "intelligence_nucleus"
        elif x < 12000:
            return "analytics_processing"
        else:
            return "interface_district"

    def _classify_architecturally(self, analysis: Dict) -> Dict:
        """Classify file architecturally based on content analysis"""
        query_matches = analysis.get('query_matches', {})

        # Determine primary domain
        if 'USER_INTERFACE' in query_matches:
            domain = "User Interface"
        elif 'AGENTIC_NATIVE' in query_matches:
            domain = "Agent Intelligence"
        elif 'POLICY_ENFORCEMENT' in query_matches:
            domain = "Security Framework"
        elif 'POKER_TABLE_PATTERN' in query_matches:
            domain = "Data Processing"
        else:
            domain = "Supporting Systems"

        # Determine layer
        if 'CORE_FOUNDATION' in query_matches:
            layer = "Foundation"
        elif 'SYMPHONY_PATTERN' in query_matches:
            layer = "Orchestration"
        elif 'PRODUCTION_READY' in query_matches:
            layer = "Implementation"
        else:
            layer = "Supporting"

        return {
            'domain': domain,
            'layer': layer,
            'significance': analysis.get('architectural_significance', 'low')
        }

    def _generate_query_intelligence(self, spatial_mapping: List[Dict]) -> Dict:
        """Generate intelligence summary across all query patterns"""

        query_summary = {}

        for query_name in self.query_tags:
            matching_files = []
            total_confidence = 0

            for entity in spatial_mapping:
                query_matches = entity['content_analysis'].get('query_matches', {})
                if query_name in query_matches:
                    matching_files.append({
                        'file': entity['file_name'],
                        'confidence': query_matches[query_name]['confidence'],
                        'zone': entity['spatial_zone']
                    })
                    total_confidence += query_matches[query_name]['confidence']

            if matching_files:
                query_summary[query_name] = {
                    'total_matches': len(matching_files),
                    'average_confidence': total_confidence / len(matching_files),
                    'matching_files': sorted(matching_files, key=lambda x: x['confidence'], reverse=True),
                    'spatial_distribution': Counter([f['zone'] for f in matching_files])
                }

        return query_summary

    def generate_sniper_report(self, output_file: str = "CANVAS_SNIPER_ANALYSIS.md"):
        """Generate comprehensive X-ray analysis report"""

        registry = self.create_canvas_atomic_registry()

        with open(output_file, 'w') as f:
            f.write("# üéØ CANVAS ATOMIC QUERY SNIPER ANALYSIS\n")
            f.write("**X-ray 4K Vision of Financial Intelligence Platform**\n\n")
            f.write(f"Generated: {registry['metadata']['generated_at']}\n\n")
            f.write("---\n\n")

            # Spatial intelligence summary
            f.write("## üó∫Ô∏è SPATIAL INTELLIGENCE SUMMARY\n\n")
            f.write(f"**Files Analyzed:** {registry['metadata']['total_files_analyzed']}\n")
            f.write(f"**Canvas Entities:** {registry['metadata']['canvas_entities_mapped']}\n")
            f.write(f"**Query Patterns:** {registry['metadata']['query_patterns_applied']}\n\n")

            # Query intelligence breakdown
            f.write("## üéØ QUERY PATTERN INTELLIGENCE\n\n")

            for query_name, query_data in registry['query_intelligence'].items():
                f.write(f"### {query_name.replace('_', ' ').title()}\n")
                f.write(f"**Matches:** {query_data['total_matches']} files\n")
                f.write(f"**Avg Confidence:** {query_data['average_confidence']:.2f}\n")
                f.write(f"**Spatial Distribution:** {dict(query_data['spatial_distribution'])}\n\n")

                # Top matching files
                f.write("**Top Matches:**\n")
                for file_info in query_data['matching_files'][:5]:
                    f.write(f"- {file_info['file']} (confidence: {file_info['confidence']:.2f}, zone: {file_info['zone']})\n")
                f.write("\n")

            # Complexity analysis
            f.write("## üìä COMPLEXITY DISTRIBUTION\n\n")
            complexity_counts = Counter()
            zone_counts = Counter()

            for entity in registry['spatial_atomic_mapping']:
                complexity = entity['content_analysis'].get('complexity_score', 'unknown')
                zone = entity['spatial_zone']
                complexity_counts[complexity] += 1
                zone_counts[zone] += 1

            f.write("**By Complexity:**\n")
            for complexity, count in complexity_counts.most_common():
                f.write(f"- {complexity.title()}: {count} files\n")

            f.write("\n**By Spatial Zone:**\n")
            for zone, count in zone_counts.most_common():
                f.write(f"- {zone.replace('_', ' ').title()}: {count} files\n")

        print(f"üìã Sniper analysis report generated: {output_file}")
        return registry

def main():
    """Execute the Canvas Atomic Query Sniper"""
    sniper = CanvasAtomicQuerySniper()
    registry = sniper.generate_sniper_report()

    print("\nüéØ SNIPER ANALYSIS COMPLETE!")
    print("üé® Canvas spatial intelligence integrated with atomic content analysis")
    print("üîç X-ray 4K vision of entire Financial Intelligence Platform achieved!")

if __name__ == "__main__":
    main()